{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Perceptron Learning\n",
    "\n",
    "The goal of this exercise is to apply the perceptron learning to a total of $N=100$ automatically generated, separable random data $X=\\bigl\\{\\vec x^1, \\vec x^2,\\ldots,\\vec x^ N \\bigr\\}$ with each $\\vec x^n = \\bigl(x_1^n, x_2^n\\bigr)^T$.\n",
    "Each data point $\\vec x^n$ is accompanied by an according target value $X=\\bigl\\{t^1, t^2,\\ldots,t^ N\\bigr\\}$ with $t^n \\in \\{-1,+1\\}$.\n",
    "\n",
    "## Data Generation\n",
    "The data should be generated such that\n",
    "$\\forall n\\leq\\frac N2\\colon \\vec x^n \\sim \\mathcal N_{\\vec\\mu_+, \\sigma_+}$.\n",
    "\n",
    "This notation indicates that for all values of $n$ that are less than or equal to half of $N$, the vector $\\vec x^n$ is approximately normally distributed with mean $\\vec\\mu_+$ and standard deviation $\\sigma_+$.\n",
    "Here, $\\mathcal N_{\\vec\\mu_+, \\sigma_+}$ represents a normal distribution with mean $\\vec\\mu_+$ and standard deviation $\\sigma_+$. The symbol $\\sim$ means \"is approximately distributed as\".\n",
    "In summary, the notation expresses that the vector $\\vec x^n$ follows a normal distribution with mean $\\vec\\mu_+$ and standard deviation $\\sigma_+$ for values of $n$ that are less than or equal to half of $N$.\n",
    "\n",
    "These samples will be our positive data labeled with $t^n=1$.\n",
    "Similarly, we generate our negative data with\n",
    "$\\forall n>\\frac N2\\colon \\vec x^n \\sim \\mathcal N_{\\vec\\mu_-, \\sigma_-}$\n",
    "and label them as $t^n=-1$.\n",
    "\n",
    "### Task 1: Data Samples\n",
    "\n",
    "Given the number of samples and the means (mu) and standard deviations (sigma) of positive (pos) and negative (neg) data, generate and return data samples including their labels. Remember to add the bias neuron $x_0=1$ to each of the samples.\n",
    "\n",
    "Hints:\n",
    "1. Use `numpy` package to generate data.\n",
    "2. Exemplary means could be selected as: $\\vec\\mu_+=(-5,3)^T$ and $\\vec\\mu_- = (5, -3)^T$. The standard deviations $\\sigma_+$ and $\\sigma_-$ should be selected such that the data is most likely separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dataset(number_of_samples, mu_pos, sigma_pos, mu_neg, sigma_neg):\n",
    "  # create positive and negative data\n",
    "  positive_data = np.random.normal(mu_pos, sigma_pos, (number_of_samples, 2))\n",
    "  negative_data = np.random.normal(mu_neg, sigma_neg, (number_of_samples, 2))\n",
    "\n",
    "  # assign positive and negative labels\n",
    "  positive_labels = np.ones((number_of_samples, 1))\n",
    "  negative_labels = np.ones((number_of_samples, -1))\n",
    "\n",
    "  # concatenate positive and negative data\n",
    "  all_data = np.concatenate((positive_data, negative_data), axis=0)\n",
    "  all_labels = np.concatenate((positive_labels, negative_labels), axis=0)\n",
    "\n",
    "  # anything else to consider?\n",
    "  ...\n",
    "\n",
    "  # return both X and T\n",
    "  return all_data, all_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Select Data Parameters and Line Parameters\n",
    "\n",
    "We want to select data points such that we exactly know where the ideal separating line should be placed.\n",
    "Note that data samples are not always separable since they are generated randomly.\n",
    "You should determine, which means and standard deviations are useful.\n",
    "\n",
    "Once you have defined your means, you should also define the separating line.\n",
    "The easiest is to provide it as Cartesian equation: $w_0 + w_1 x_1 + w_2 x_2$.\n",
    "Note that the separating line is orthogonal to the vector $\\overrightarrow{\\vec\\mu_- \\vec\\mu_+}$, that the normal of the line $(w_1, w_2)^T$ is orthogonal to the line, and that $w_0$ should be selected such that the line $\\vec w$ is in the middle of $\\vec\\mu_+$ and $\\vec\\mu_-$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dataset() missing 3 required positional arguments: 'sigma_pos', 'mu_neg', and 'sigma_neg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X, T \u001b[39m=\u001b[39m dataset(\u001b[39m100\u001b[39;49m, \u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m w_manual \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: dataset() missing 3 required positional arguments: 'sigma_pos', 'mu_neg', and 'sigma_neg'"
     ]
    }
   ],
   "source": [
    "X, T = dataset(100, ...)\n",
    "\n",
    "w_manual = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Linear Separability Test\n",
    "\n",
    "A line $a = f_{\\vec w}(\\vec x) = w_0 + w_1 x_1 + w_2 x_2$ linearly separates the data $(X,T)$ if $\\forall n: a^{[n]} t^{[n]} > 0$ for $a^{[n]} = f_{\\vec w}(\\vec x^{[n]})$.\n",
    "The below function implements this linear separability test. We apply this test to your data $(X,T)$ from Task 1 and your manually selected line $\\vec w$ from Task 2 to assure that the line separates the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "\u001b[1;31m[notice] To update, run: /Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def separability_test(X, T, w):\n",
    "  return numpy.all(numpy.dot(X,w) * T > 0)\n",
    "\n",
    "# Test 1: check that the weights are separating the data\n",
    "if separability_test(X, T, w_manual):\n",
    "  print(\"The data is separated by the manually selected line\")\n",
    "else:\n",
    "  print(\"The anually selected line does not separate the data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Perceptron\n",
    "\n",
    "The perceptron is defined as the Adaline $$a = f_{\\vec w}(\\vec x)$$ that is thresholded using the sign function $$\\mathrm{sign}(a) = \\begin{cases} +1 &\\text{if } a \\geq 0\\\\ -1 & \\text{otherwise.}\\end{cases}$$\n",
    "Implement a function that computes and returns the perceptron for a given data point $\\vec x$ and line parameters $\\vec w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "\u001b[1;31m[notice] To update, run: /Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def perceptron(x, w):\n",
    "  ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Learning\n",
    "\n",
    "The perceptron learning rule is defined as follows.\n",
    "First, the weights $\\vec w = (w_0, w_1, w_2)^T$ is initialized randomly.\n",
    "Then, for each sample $(x,t)$ of the dataset we check if the sample is correctly classified as $H(f_{\\vec w}(\\vec x)) t > 0$.\n",
    "If the sample is classified incorrectly, the weights are adapted: $w_0 = w_0 + t$, $w_1 = w_1 + tx_1$, $w_2 = w_2 + tx_2$.\n",
    "This step is repeated until all samples are classified correctly.\n",
    "\n",
    "\n",
    "### Task 4: Perceptron Learning Implementation\n",
    "\n",
    "Implement a function that performs perceptron learning for a given dataset $(X,T)$ and a given initial weight vector $\\vec w$.\n",
    "The final weight vector $\\vec w^*$ shall be returned from that function.\n",
    "Define a proper stopping criterion for the iteration.\n",
    "Consider in your implementation error cases that could arise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "\u001b[1;31m[notice] To update, run: /Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def perceptron_learning(X, T, w):\n",
    "  # first, make a copy of your weights\n",
    "  w_star = ...\n",
    "\n",
    "  # then, iterate over the data and perform perceptron learning\n",
    "  ...\n",
    "  \n",
    "  # finally, return the optimal weights\n",
    "  return w_star"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Sanity Check\n",
    "\n",
    "We call the perceptron learning function with the data from task 1 and the manual line from task 2. If the line separates the data, it should not be changed. Here we test if this is the actual outcome of the perceptron learning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "\u001b[1;31m[notice] To update, run: /Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "w_star = perceptron_learning(X, T, w_manual)\n",
    "\n",
    "# check if the output is as expected\n",
    "if numpy.any(w_manual != w_star):\n",
    "    print(\"Warning: the perceptron algorithm seems to be wrong\")\n",
    "else:\n",
    "    print(\"As desired, perceptron learning does not optimize an already separating line\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Weight Initialization\n",
    "\n",
    "Implement a function that generates and returns randomly initialized weights $\\vec w \\in [-1,1]^3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "\u001b[1;31m[notice] To update, run: /Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def random_weights(lowest = -1, highest = 1):\n",
    "  ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Perceptron Learning Execution\n",
    "\n",
    "Call the perceptron learning function with the data from task 1 and the randomly generated initial weight vector from task 5.\n",
    "Store the resulting weight vector $\\vec w^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "\u001b[1;31m[notice] To update, run: /Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# create random weights\n",
    "w_initial = random_weights()\n",
    "\n",
    "# perform perceptron learning\n",
    "w_star = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Result Validation\n",
    "\n",
    "We verify that the optimized $\\vec w^*$ actually separates the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "\u001b[1;31m[notice] To update, run: /Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# verify that we have learned to separate the data\n",
    "if separability_test(X, T, w_star):\n",
    "  print(\"The data is separated by the optimal line\")\n",
    "else:\n",
    "  print(\"The optimal line does not separate the data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "We have selected our data to be 2-dimensional to be able to visualize the results.\n",
    "For this purpose, we would like to jointly plot the positive and the negative data from Task 1 together with the decision boundaries of the weight vectors obtained in Tasks 2 and 6.\n",
    "An example can be found in the exercise slides.\n",
    "\n",
    "### Task 7: Plotting\n",
    "\n",
    "First, we need to plot the data points such that positive data are plotted with green dots, and negative data with red dots.\n",
    "\n",
    "Then, we need to compute the line parameters. For this purpose, we define the separating line in Cartesian coordinates $f_{\\vec w}(\\vec x) = 0$ and solve it to the parametric form $x_2 = \\beta x_1 + \\gamma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31m[notice] A new release of pip available: 22.3 -> 23.0.1\n",
      "\u001b[1;31m[notice] To update, run: /Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def line_parameters(w):\n",
    "  # compute parametric line parameters from Cartesian coordinates\n",
    "  beta = ...\n",
    "  gamma = ...\n",
    "  return beta, gamma\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# create a square plot\n",
    "pyplot.figure(figsize=(8,8))\n",
    "\n",
    "# plot the positive data points\n",
    "pyplot.plot(..., ..., \"g.\", label=\"positive data\")\n",
    "# plot the negative data points\n",
    "pyplot.plot(..., ..., \"r.\", label=\"negative data\")\n",
    "\n",
    "# define positions where to evaluate the line:\n",
    "x1 = ...\n",
    "\n",
    "# compute line parameters for manual line\n",
    "beta, gamma = line_parameters(w_manual)\n",
    "# now, compute the values according to our parametric form:\n",
    "x2 = beta * x1 + gamma\n",
    "# plot lines (might need to call this function twice for the two lines)\n",
    "pyplot.plot(x1, x2, \"m-\", label=\"manual line\")\n",
    "\n",
    "# compute line parameters for optimized line\n",
    "beta, gamma = line_parameters(w_star)\n",
    "# now, compute the values according to our parametric form:\n",
    "x2 = beta * x1 + gamma\n",
    "# plot lines (might need to call this function twice for the two lines)\n",
    "pyplot.plot(x1, x2, \"b-\", label=\"optimized line\")\n",
    "\n",
    "# make the plot more beautiful\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f94a2e1669021a1b826617800504e937bcc4e1c8d0dde6e9bfebb8455f6fae62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
