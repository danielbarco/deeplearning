{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Classification in PyTorch \n",
    "\n",
    "\n",
    "For this exercise, we will switch to an implementation in PyTorch. \n",
    "The goal of this exercise is to get used to some concepts in PyTorch, such as relying on the `torch.tensor` data structure, implementing the network, the loss functions, the training loop and accuracy computation, which we will apply to binary and categorical classification.\n",
    "\n",
    "Please make sure that all your variables are compatible with `torch`.\n",
    "For example, you cannot mix `torch.tensor`s and `numpy.ndarray`s in any part of the code.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We will use two different datasets, the *spambase* dataset https://archive.ics.uci.edu/ml/datasets/spambase for binary classification and the *wine* dataset https://archive.ics.uci.edu/ml/datasets/wine for categorical classification. Both datasets are available on the UCI Machine Learning repository. \n",
    "The binary classification dataset contains features extracted from emails, which are classified as either spam or not. \n",
    "The categorical classification dataset contains some manually selected features for three different types of wines. \n",
    "For the former, the class is provided in the last column of the data file, whereas for the latter, the first index provides class information.\n",
    "\n",
    "Please run the code block below to download the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# download the two dataset files\n",
    "dataset_files = {\n",
    "  \"spambase.data\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/\",\n",
    "  \"wine.data\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/\"\n",
    "}\n",
    "for name, url in dataset_files.items():\n",
    "  if not os.path.exists(name):\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(url+name, name)\n",
    "    print (\"Downloaded datafile\", name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Dataset Loading\n",
    "\n",
    "The first task deals with the loading of the datasets. \n",
    "When training networks in PyTorch, all data needs to be stored as datatype ``torch.tensor``. \n",
    "The data should be split between input sets $\\mathbf X = [\\vec x^{[1]}, \\ldots, \\vec x^{[N]}]^T \\in \\mathbb R^{N\\times D}$ and targets.\n",
    "There is **no need to add a bias neuron to the input**, and the transposition of the data matrix is different from what we have seen before.\n",
    "\n",
    "For the targets, we have to be more careful as there are differences w.r.t. the applied loss function.\n",
    "For binary classification, we need $\\mathbf T = [[t^{[1]}, \\ldots, t^{[N]}]]$ to be in dimension $\\mathbb R^{N\\times1}$ and of type ``torch.float``.\n",
    "For categorical classification, we only need the class indexes $\\vec t = [t^{[1]}, \\ldots, t^{[N]}]$ to be in dimension $\\mathbb N^N$ and of type ``torch.long``.\n",
    "\n",
    "Implement a function that returns both the input and the target data for a given dataset\n",
    "\n",
    "Note:\n",
    "\n",
    "1. You can use `csv.reader()` to read the dataset, or rely on other methods such as `pandas`.\n",
    "2. For the wine dataset, subtract the target by `-1` to get the target values in range $\\{0, 1, 2\\}$.\n",
    "3. Be aware both datasets are sorted w.r.t. their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(dataset_file=\"wine.data\"):\n",
    "  # read dataset\n",
    "  data = []\n",
    "  with open(dataset_file, 'r') as f:\n",
    "    ...\n",
    "\n",
    "  print (f\"Loaded dataset with {len(data)} samples\")\n",
    "  \n",
    "  # convert to torch.tensor\n",
    "  ...\n",
    "\n",
    "  if dataset_file == \"wine.data\":\n",
    "    # target is in the first column and needs to be converted to long\n",
    "    X = ...\n",
    "    T = ...\n",
    "  else:\n",
    "    # target is in the last column and needs to be of type float\n",
    "    X = ...\n",
    "    T = ...\n",
    "  return X, T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Dataset Check\n",
    "\n",
    "Test 1 assures the correctness of the data and target dimensions.\n",
    "\n",
    "1. For the wine dataset, we make sure that the dataset is in the correct dimensions, i.e., $\\mathbf X\\in \\mathbb R^{N\\times D}$ and $\\mathbf T \\in \\mathbb N^N$. And all class labels are in the correct range $[0, O-1]$ where $O$ is the number of classes.\n",
    "\n",
    "2. For the spambase data, we assure that all dimensions are correct and that class labels are in range $\\{0, 1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, T = dataset(\"wine.data\")\n",
    "\n",
    "assert X.shape[1] == 13, X.shape[1]\n",
    "assert torch.all(T >= 0) and torch.all(T <= 2)\n",
    "assert T.dtype == torch.long\n",
    "\n",
    "X, T = dataset(\"spambase.data\")\n",
    "assert X.shape[1] == 57, X.shape[1]\n",
    "assert T.shape[1] == 1, T.shape[1]\n",
    "assert torch.all(T >= 0) and torch.all(T <= 1)\n",
    "assert T.dtype == torch.float"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Split Training and Validation Data\n",
    "\n",
    "The data should be split into 80% for training and 20% for validation. Implement a function that takes the full dataset $(X,T)$ and returns $(X_t, T_t, X_v, T_v)$ accordingly.\n",
    "\n",
    "Write a function that splits off training and validation samples from a given dataset. What do we need to assure before splitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_data(X,T,train_percentage=0.8):\n",
    "  \n",
    "  # split into 80/20 training/validation\n",
    "  X_train = ...\n",
    "  T_train = ...\n",
    "  X_val = ...\n",
    "  T_val = ...\n",
    "\n",
    "  return X_train, T_train, X_val, T_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Input Data Standardization\n",
    "\n",
    "As we have seen last week, the standardization of the data provides many advantages. \n",
    "Hence, in this task you should write a function that takes $(X_t,X_v)$ as input and standardizes them by subtracting the mean and dividing by the \n",
    "standard deviation of $X_t$, and returning the standardized versions of both. Assure that each input dimension is standardized individually.\n",
    "\n",
    "Implement a function that standardizes all input data for the training and validation set.\n",
    "Return the standardized data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "1. Use `torch.mean()` and `torch.std()` with the correct dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train, X_val):\n",
    "  # compute statistics\n",
    "  mean = ...\n",
    "  std = ...\n",
    "\n",
    "  # standardize both X_train and X_val\n",
    "  ...\n",
    "  return X_train, X_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Implementation\n",
    "\n",
    "We will use a two-layer fully-connected network with $D$ input neurons, $K$ hidden neurons and $O$ output neurons. \n",
    "Depending on the task, $D$ and $O$ need to be selected appropriately, while $K$ is a parameter to play around with. \n",
    "In PyTorch, the easiest way to implement a network is by providing the requested sequence of layers to `torch.nn.Sequential`, which will build a network containing the given layers. \n",
    "We will use two `torch.nn.Linear` layers and one `torch.nn.Tanh` activation function in between. \n",
    "The network will return the logits $\\vec z$ for a given input $\\vec x$.\n",
    "\n",
    "\n",
    "### Task 4: Implement Network\n",
    "\n",
    "Implement a two-layer fully-connected network in PyTorch. \n",
    "The given network uses $\\tanh$ as activation function, and provide the possibility to change the number of inputs $D$, the number of hidden neurons $K$ and the number of outputs $O$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def Network(D, K, O):\n",
    "  return torch.nn.Sequential(\n",
    "    ...\n",
    "  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Accuracy Computation\n",
    "\n",
    "To monitor the training process, we want to compute the accuracy. \n",
    "The function will obtain the logits $\\vec z$ extracted from the network and the according target $t$. \n",
    "Assure that this function works both for binary and categorical classification. \n",
    "How can we identify, which of the two variants is currently required?\n",
    "\n",
    "Note: you can make use of the following pytorch functions:\n",
    "\n",
    "1. `torch.mean()` which computes the mean or average of the input tensor.\n",
    "2. `torch.argmax()` which returns the indices of the maximum values of all elements of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Z, T):\n",
    "  # check if we have binary or categorical classification\n",
    "  if ...:\n",
    "    # binary classification\n",
    "    return ...\n",
    "  else:\n",
    "    # categorical classification\n",
    "    return ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Test Accuracy Function\n",
    "\n",
    "Test 2 assures the correctness of your accuracy function in both binary and categorical cases. We make sure that the accuracy will compute the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, test binary classification\n",
    "ZZ = torch.ones((20,1)) * -5.\n",
    "ZZ[15:20] = 5\n",
    "assert(abs(accuracy(ZZ,torch.zeros((20,1))) - 0.75) < 1e-8)\n",
    "assert(abs(accuracy(ZZ,torch.ones((20,1))) - 0.25) < 1e-8)\n",
    "\n",
    "# now, test categorical classification with 4 classes\n",
    "ZZ = torch.ones((20,4)) * -5\n",
    "ZZ[0:1,0] = 5\n",
    "ZZ[1:4,1] = 5\n",
    "ZZ[4:10,2] = 5\n",
    "ZZ[10:20,3] = 5\n",
    "\n",
    "assert(abs(accuracy(ZZ,torch.zeros(20)) - 0.05) < 1e-8)\n",
    "assert(abs(accuracy(ZZ,torch.ones(20)) - 0.15) < 1e-8)\n",
    "assert(abs(accuracy(ZZ,torch.ones(20)*2) - 0.3) < 1e-8)\n",
    "assert(abs(accuracy(ZZ,torch.ones(20)*3) - 0.5) < 1e-8)\n",
    "assert(abs(accuracy(ZZ,torch.tensor((0,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3))) - 1.) < 1e-8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Training Loop\n",
    "\n",
    "Implement a function that takes all necessary parameters to run a training on a given dataset.\n",
    "In this week, we will run gradient descent, i.e., we will train on the whole dataset in each training step, so there is no need to define anything related to batches. \n",
    "Select the optimizer to be `torch.optim.SGD`. \n",
    "\n",
    "Implement a training loop over 10'000 epochs with a learning rate of $\\eta=0.1$. \n",
    "Make sure that you train on the training data only, and **not** on the validation data.\n",
    "In each loop, compute and store the training loss, training accuracy, validation loss and validation accuracy. \n",
    "At the end, return the lists of these values.\n",
    "\n",
    "Note:\n",
    "\n",
    "1. When storing accuracy or loss values in a list, make sure to convert the to float via `v.item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(...):\n",
    "  optimizer = ...\n",
    "\n",
    "  # collect loss and accuracy values\n",
    "  train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "\n",
    "  for epoch in ...:\n",
    "    # train on training set\n",
    "    # ... compute network output on training data\n",
    "    ...\n",
    "    # ... compute loss from network output and target data\n",
    "    ...\n",
    "    # ... perform parameter update\n",
    "    ...\n",
    "    # ... remember loss\n",
    "    train_loss.append(...)\n",
    "    # ... compute training set accuracy\n",
    "    train_acc.append(...)\n",
    "\n",
    "    # test on validation data\n",
    "    with torch.no_grad():\n",
    "      # ... compute network output on validation data\n",
    "      ...\n",
    "      # ... compute loss from network output and target data\n",
    "      ...\n",
    "      # ... remember loss\n",
    "      val_loss.append(...)\n",
    "      # ... compute validation set accuracy\n",
    "      val_acc.append(...)\n",
    "\n",
    "  # return the four lists of losses and accuracies\n",
    "  return train_loss, train_acc, val_loss, val_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n",
    "\n",
    "Finally, we want to train our network on our data and plot the accuracy and loss values that were obtained through the epochs. \n",
    "Exemplary plots can be found in the exercise slides.\n",
    "\n",
    "\n",
    "### Task 7: Plotting Function\n",
    "\n",
    "Implement a function that takes four lists containing the training loss, the training accuracy, the validation loss and the validation accuracy and plot them into two plots. \n",
    "The first plot should contain the loss values for both training and validation. The second plot should contain the according accuracy values.\n",
    "\n",
    "Note:\n",
    "\n",
    "1. You might need to convert remaining `torch.tensor` values to `float`, lists, or `numpy.nadrray` for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "def plot(train_loss, train_acc, val_loss, val_acc):\n",
    "  pyplot.figure(figsize=(10,3))\n",
    "  ax = pyplot.subplot(121)\n",
    "  ax.plot(..., \"g-\", label=\"Training set loss\")\n",
    "  ax.plot(..., \"b-\", label=\"Validation set loss\")\n",
    "  ax.legend()\n",
    "\n",
    "  ax = pyplot.subplot(122)\n",
    "  ax.plot(..., \"g-\", label=\"Training set accuracy\")\n",
    "  ax.plot(..., \"b-\", label=\"Validation set accuracy\")\n",
    "  ax.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Binary Classification\n",
    "\n",
    "\n",
    "1. Load the data for binary classification, using the ``\"spambase.data\"`` file.\n",
    "2. Split the data into training and validation sets.\n",
    "3. Standardize both training and validation input data using the function from Task 3.\n",
    "4. Instantiate a network with the correct number of input neurons, a reasonable number of $K$ hidden neurons and one output neuron.\n",
    "\n",
    "Which loss function do we need for this task?\n",
    "\n",
    "Train the network with our data for 10'000 epochs and plot the training and validation accuracies and losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "loss = ...\n",
    "# load dataset\n",
    "X, T = ...\n",
    "# split dataset\n",
    "X_train, T_train, X_val, T_val = ...\n",
    "# standardize input data\n",
    "X_train, X_val = ...\n",
    "# instantiate network\n",
    "network = ...\n",
    "\n",
    "# train network on our data\n",
    "results = ...\n",
    "\n",
    "# plot the results\n",
    "plot(...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Categorical Classification\n",
    "\n",
    "Perform the same tasks with the ``\"wine.data\"`` dataset for categorical classification. \n",
    "How many input and output neurons do we need?\n",
    "Change the number of input, hidden, and output neurons accordingly.\n",
    "\n",
    "Select the appropriate loss function for categorical classification.\n",
    "Which loss function will we need this time?\n",
    "\n",
    "How many hidden neurons will we need to get 100% training set accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "loss = ...\n",
    "# load dataset\n",
    "X, T = ...\n",
    "# split dataset\n",
    "X_train, T_train, X_val, T_val = ...\n",
    "# standardize input data\n",
    "X_train, X_val = ...\n",
    "# instantiate network\n",
    "network = ...\n",
    "\n",
    "# train network on our data\n",
    "results = ...\n",
    "\n",
    "# plot the results\n",
    "plot(...)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
