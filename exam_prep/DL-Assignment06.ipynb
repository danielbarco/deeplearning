{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"eH27MSc7aQLq"},"source":["# Assignment 6: Convolutional Networks\n","\n","Before we start, we should assure that we have activated CUDA -- otherwise training might take very long.\n","In Google Colaboratory:\n","\n","1. Check the options Runtime -> Change Runtime Type on top of the page.\n","2. In the popup window, select hardware accelerator GPU.\n","\n","Afterward, the following command should run successfully:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4448,"status":"ok","timestamp":1677241993135,"user":{"displayName":"Xinyi Zhang","userId":"00376105640142165248"},"user_tz":-60},"id":"jPstyY7AaQLv","outputId":"94c07ab8-d6ab-4ef1-8c6c-b3a54de1ba58"},"outputs":[],"source":["import torch\n","if torch.cuda.is_available():\n","  print(\"Successfully enabled CUDA processing\")\n","else:\n","  print(\"CUDA processing not available. Things will be slow :-(\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"W08ImtCeaQLw"},"source":["## Dataset\n","\n","In PyTorch, a dataset stores a list of input and target tensors $(X^n, T^n)$.\n","In case of **MNIST** dataset, the inputs are $X^n \\in \\mathbb R^{28\\times28}$ and $T^n \\in \\{0,\\ldots,9\\}$.\n","More precisely, the data in the dataset is provided in form of `PIL.Image.Image`, which represents an image class with some more functionality, and pixel values in range $[0, 255]$.\n","In order to convert these images into `torch.Tensor`'s in range $[0,1]$, we can use the [ToTensor](https://pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html) transform.\n","Furthermore, in `PyTorch` batches are created from datasets using the [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"q9s7rhj4iDKu"},"source":["\n","### Task 1: Dataset Loading\n","\n","\n","Here, we use the [MNIST dataset](https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html) of gray images for categorical classification.\n","\n","Write a function that returns the training and the testing set of MNIST, using the given transform."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UdAXKwqUaQLx"},"outputs":[],"source":["import torch\n","import torchvision\n","\n","def datasets(transform):\n","  trainset = torchvision.datasets.MNIST()\n","  testset = torchvision.datasets.MNIST(...)\n","\n","  return trainset, testset"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2Abp751vaQLx"},"source":["### Test 1: Data Types\n","\n","When we create the dataset with `transform=None`, all inputs shall be of type `PIL.Image.Image`, and all targets are integral."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hAMpr6hhaQLx"},"outputs":[],"source":["import PIL\n","trainset, testset = datasets(transform=None)\n","\n","for x,t in trainset:\n","  # check datatype of input x\n","  assert isinstance(x, PIL.Image.Image)\n","  # check datatype of target t\n","  assert isinstance(t, int)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rEhGkNEdaQLy"},"source":["### Task 2: Data Loaders\n","\n","\n","Create the dataset with transform `ToTensor`. Create two data loaders, one for the training set and one for the testing set. The training batch size should be $B=64$, for the testing set, you can select any batch size of your choice.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72TgSAmDaQLy"},"outputs":[],"source":["transform = ...\n","trainset, testset = datasets(transform=transform)\n","\n","B = 64\n","trainloader = torch.utils.data.DataLoader(...)\n","testloader = torch.utils.data.DataLoader(...)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_VmIeKXQaQLz"},"source":["### Test 2: Batches\n","\n","Check that all batches generated by the training set data loader have the batch size of $B$ -- except for the last batch, which you need to compute by yourself (you might want to make use of the modulo operator `%`).\n","\n","Afterward, we check that all inputs and targets are of type `torch.Tensor`, that all input values are in range $[0,1]$ and that all target values are in range $[0,9]$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQ-wtDlPaQL0"},"outputs":[],"source":["# compute the size of last batch\n","last_batch = ...\n","\n","for x,t in trainloader:\n","  # check datatype, size and content of x\n","  assert isinstance(x, torch.Tensor)\n","  assert(torch.all(x >= 0)) and torch.all(x <= 1)  \n","  assert len(x)==B or len(x) == last_batch\n","\n","  # check datatype, size and content of t\n","  assert isinstance(t, torch.Tensor)\n","  assert(torch.all(t >= 0)) and torch.all(t <= 9)\n","  assert len(t)==B or len(t) == last_batch"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HCcVzXbiaQL0"},"source":["## Networks\n","As last week, we will rely on [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) to create networks with particular lists of consecutive layers.\n","Particularly, we will investigate two different versions of networks, one fully-connected network and one convolutional network, with the same number of learnable layers.\n","\n","### Task 3: Fully-Connected Network\n","\n","\n","Implement a function that returns a three-layer fully-connected network in `pytorch`.\n","Use $\\tanh$ as activation function between the two fully-connected layers, and provide the possibility to change the number of inputs $D$, the number of hidden neurons $K$ and the number of outputs $O$.\n","Use the following layers:\n","\n","1. A [Flatten layer](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) to turn the $28\\times28$ pixel image (2D) into a $28\\cdot28$ pixel vector (1D).\n","2. A [fully-connected layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) with D input neurons and K outputs.\n","3. A [$\\tanh$ activation function](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html).\n","4. A fully-connected layer with K input neurons and K outputs.\n","5. A $\\tanh$ activation function.\n","6. A fully-connected layer with K input neurons and O outputs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kUllttuBaQL0"},"outputs":[],"source":["def fully_connected(D, K, O):\n","  return torch.nn.Sequential(\n","    ...\n","  )"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_nL0shNEaQL1"},"source":["### Task 4: Convolutions Output (theoretical question)\n","\n","Consider the network as defined in Task 5.\n","Assume that the input is a $28\\times28$ grayscale image.\n","How many hidden neurons do we need in the final fully-connected layer for a given number $Q_2$ of output channels of the second convolution?\n","\n","..."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OkWbJWGbaQL1"},"source":["### Task 5: Convolutional Network\n","\n","Implement a function that generates a convolutional network with the following layers:\n","\n","1. A [2D convolutional layer](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) with $Q_1$ channels, kernel size $5\\times5$, stride 1 and padding 2.\n","2. A [2D maximum pooling](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) with pooling size $2\\times2$ and stride 2.\n","3. A $\\tanh$ activation function.\n","4. A 2D convolutional layer with $Q_2$ channels, kernel size $5\\times5$, stride 1 and padding 2.\n","5. A 2D maximum pooling with pooling size $2\\times2$ and stride 2.\n","6. A $\\tanh$ activation function.\n","7. A flattening layer to turn the 3D feature map into a 1D vector.\n","8. A fully-connected layer with the appropriate number of inputs and $O$ outputs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mS9cuYsSaQL1"},"outputs":[],"source":["def convolutional(Q1, Q2, O):\n","  return torch.nn.Sequential(\n","    ...\n","  )"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6IL7ji_qaQL2"},"source":["## Network Training\n","For training and evaluating the network, we rely on standard functionality in PyTorch.\n","We use the standard [categorical cross-entropy loss](https://pytorch.org/docs/stable/nn.html#loss-functions) together with a [stochastic gradient descent](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) optimizer.\n","For training, we use the batched implementation of the dataset, for which we perform one update step for each training batch.\n","After having gone through the full training dataset, we compute accuracy and loss values for the testing set (we simply make use of the testing set for validation).\n","\n","\n","### Task 6: Training and Validation Loop\n","\n","Implement a function that takes the network, the number of epochs, and the learning rate.\n","Select the correct loss function for categorical classification and SGD optimizer.\n","Iterate the following steps for the given number of epochs:\n","\n","1. Train the network with all batches of the training data.\n","2. Compute the testing set loss and testing set accuracy.\n","3. Store both in a vector.\n","\n","What do we need to take care of?\n","\n","Finally, return the lists of validation losses and accuracies."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8q12fyYaQL2"},"outputs":[],"source":["def train(network, epochs, eta, momentum):\n","  # select loss function and optimizer\n","  loss = ...\n","  optimizer = ...\n","\n","  # instantiate the correct device\n","  device = torch.device(\"cuda\")\n","  network = network.to(device)\n","\n","  # collect loss values and accuracies over the training epochs\n","  val_loss, val_acc = [], []\n","\n","  for epoch in range(epochs):\n","    # train network on training data\n","    for x,t in trainloader:\n","      # put data to device\n","      ...\n","      # train\n","      ...\n","\n","    # test network on test data\n","    with torch.no_grad():\n","      for x,t in testloader:\n","        # put data to device\n","        ...\n","        # compute validation loss\n","        ...\n","        # compute validation accuracy\n","        ...\n","\n","\n","  # return loss and accuracy values\n","  return val_loss, val_acc"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tEssOE_PaQL2"},"source":["### Task 7: Fully-Connected Training\n","\n","Create a fully-connected network with $K=100$ hidden and $O=10$ output neurons.\n","Train the network for 10 epochs with $\\eta=0.01$, $momentum=0.9$ and store the obtained test losses and accuracies.\n","Brave people can also train for 100 epochs (which will take up to 30 minutes)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EjW7zpuvaQL2"},"outputs":[],"source":["fc = fully_connected(...)\n","fc_loss, fc_acc = train(...)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eGW5qI6naQL3"},"source":["### Task 8: Convolutional Training\n","\n","\n","Create a convolutional network with $Q_1=16$ and $Q_2=32$ convolutional channels and $O=10$ output neurons.\n","Train the network for 10 epochs with $\\eta=0.01$, momentum $=0.9$ and store the obtained test losses and accuracies.\n","Again, 100 epochs will take up to 30 minutes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4hQSxjIEaQL3"},"outputs":[],"source":["cv = convolutional(...)\n","cv_loss, cv_acc = train(...)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"R2lhQiuyaQL3"},"source":["### Task 9: Plotting\n","\n","Plot the two lists of loss values in one plot. Plot the two lists of accuracy values into another plot."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SMsfktXaQL3"},"outputs":[],"source":["from matplotlib import pyplot\n","pyplot.figure(figsize=(10,3))\n","ax = pyplot.subplot(121)\n","# plot loss values of FC and CV network over epochs\n","...\n","\n","ax = pyplot.subplot(122)\n","# plot accuracy values of FC and CV network over epochs\n","..."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vua5OAWnaQL3"},"source":["### Task 10: Learnable Parameters \n","\n","Estimate roughly how many learnable parameters the two networks have by analytically computing and adding the number of parameters in each layer.\n","\n","Fully-connected Network:\n","- first fully-connected layer: ...\n","- second fully-connected layer: ...\n","- third fully-connected layer: ...\n","- total: ...\n","\n","Convolutional Network:\n","- first convolutional layer: ...\n","- second convolutional layer: ...\n","- fully-connected layer: ...\n","- total: ...\n","\n","\n","\n","Now, compute the number of parameters in the networks by summing the number of parameters in each layer using `pytorch` functionality.\n","You can use the `numel()` function from a `torch.Tensor` to provide the number of (learnable) parameters stored in a tensor.\n","How do you obtain this list of all learnable parameters from a `pytorch` [Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aC_ZOtKUaQL4"},"outputs":[],"source":["def parameter_count(network):\n","  return ...\n","\n","print(\"Fully-connected Network:\", parameter_count(fc))\n","print(\"Convolutional Network:\", parameter_count(cv))"]}],"metadata":{"colab":{"provenance":[]},"interpreter":{"hash":"2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"},"kernelspec":{"display_name":"Python 3.8.10 ('DL')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
