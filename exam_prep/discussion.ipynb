{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 3 (p.11) why do we need an activation for non-linearity? Why do we need a transform to multiply the weights(2) with the activation and the W(1)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 3 (p.41) why do we have a dimension mismatch and how do we solve it (Vectorizing Computation)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 5 (p.19) why does BCE loss turn L2 loss into binary classification by adding sigma(z) <br>\n",
    "ðŸ’¡ sigma stands for sigmoid function which outputs a number between 0 and 1, which is great for probabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are logits only for classification problems? <br>\n",
    "CHAT-GPT So, while the term \"logits\" is commonly associated with classification problems, it is not exclusively limited to them. It refers to the unnormalized values produced by a model before applying a final activation function or transformation, and it can be utilized in various types of machine learning tasks beyond classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need two Jacobian matrices for each operation $\\overrightarrow{z} = W^{(2)} * \\overrightarrow{h}$ ? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
