{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mmm_fi2REAI"
      },
      "source": [
        "### 1. (f) Network Implementation\n",
        "\n",
        "We implement our network to combine the first layer with an activation function, and a fully-connected layer to produce our desired output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "XCwwwj3TREAJ",
        "outputId": "6c67073f-72e8-4611-8109-af2847e561ef"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-20073775c87d>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    self.activation = torch.nn.()\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "class Network(torch.nn.Module):\n",
        "  def __init__(self, K, D):\n",
        "    super(Network, self).__init__()\n",
        "    # we select our function defined above as the first layer that we apply\n",
        "    self.first_layer = \n",
        "\n",
        "    # We need to instantiate and initialize our weights\n",
        "    self.W = \n",
        "    # initialize the matrix between -3 and 3 (since the range of the inputs is (-3,3))\n",
        "    torch.nn.init.uniform_(self.W, -3, 3)\n",
        "\n",
        "    # We then instantiate the second fully-connected layer\n",
        "    self.secoond_layer = #since this is a regression, the output is O=1\n",
        "\n",
        "    # anything else to instantiate here?\n",
        "    self.activation = \n",
        "\n",
        "  def forward(self, x):\n",
        "    # forward input through our custom function\n",
        "    a = \n",
        "    \n",
        "    # possibly apply an activation function\n",
        "    h = \n",
        "\n",
        "    # apply second layer\n",
        "    z = \n",
        "\n",
        "    return z\n",
        "\n",
        "# instantiate a network with the desired parameters\n",
        "network = Network(6, D=x.shape[0]) #D could also have been defined like this in the constructor of Nework"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bPMDXn5TREAL"
      },
      "source": [
        "We implement a function that draws random samples from the input distribution.\n",
        "You can make use of this function, there is no need to modify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aooWtR-REAM"
      },
      "outputs": [],
      "source": [
        "# provides a sample from the function that we want to approximate\n",
        "def sample():\n",
        "  # get a random input\n",
        "  x = torch.rand(2) * 6 - 3\n",
        "  # compute the target\n",
        "  t = data(x[0], x[1])[None]\n",
        "  # return both\n",
        "  return x, t"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tIDq6FIzREAN"
      },
      "source": [
        "### 1. (g) Network Training\n",
        "\n",
        "Finally, we train our network on 100000 samples, using a batch size of 1. We report the average loss for 10000 samples once they are processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNkl1AcLREAO"
      },
      "outputs": [],
      "source": [
        "# instantiate loss function and optimizer\n",
        "loss = torch.nn.MSELoss()\n",
        "optimizer = optimizer = torch.optim.Adam(network.parameters(), lr=0.0005, weight_decay=1e-05)\n",
        "\n",
        "#create variable to store train loss\n",
        "train_loss = 0.\n",
        "\n",
        "# iterate over 100000 samples\n",
        "for i in range(100000):\n",
        "  # obtain a sample\n",
        "  x, t = sample()\n",
        "  # train the network with this sample\n",
        "  optimizer.zero_grad()\n",
        "  z=network(x)\n",
        "  # ... compute loss from network output and target data\n",
        "  J=loss(z, x)\n",
        "  J.backward()\n",
        "  # ... perform parameter update\n",
        "  optimizer.step()\n",
        "  # ... remember loss\n",
        "  train_loss += J.item()\n",
        "\n",
        "  # compute average loss\n",
        "  avg_loss = train_loss/100000.\n",
        "  # report it after every 10000 iterations\n",
        "  if i % 10000 == 9999:\n",
        "    return avg_loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XdLR2cLKREAO"
      },
      "source": [
        "Finally, we plot the output of your network to visually see whether the data has been approximated well.\n",
        "We actually extend the range of the input samples to be $[-5,5]$ to see if the network has learned to extend the function well beyond the training range.\n",
        "Note that this is just for visualization purposes, you do not need to change this part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm9a8FGcREAP"
      },
      "outputs": [],
      "source": [
        "# define a range a little larger than our input range\n",
        "rge = numpy.arange(-5,5,0.1)\n",
        "X,Y = numpy.meshgrid(rge, rge)\n",
        "# compute the result of our network for the given range [-5,5]x[-5,5]\n",
        "Z = numpy.array([[network(torch.FloatTensor((X[i,j], Y[i,j]))).item() for j in range(len(rge))] for i in range(len(rge))])\n",
        "# plot the results\n",
        "plot_3d(X,Y,Z)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DL-FS22-Exam-Task1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a29cabff5744fce69e08a959ab87b9e77a9f67b498d08783caa8c3bb16f23a00"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('DL')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
