{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmjwgutHRD_3"
      },
      "source": [
        "# 1. Function Approximation\n",
        "\n",
        "We want to approximate a function with two inputs and one output.\n",
        "This function can be interpreted as 3-dimensional plot $t=f(x_1,x_2)$.\n",
        "We first provide a plotting function to visualize the data and the resulting network output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUBYDYBHRD_9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from matplotlib import pyplot\n",
        "import numpy\n",
        "\n",
        "# a plotting function to show the data and the result\n",
        "def plot_3d(X, Y, Z):\n",
        "  f = pyplot.figure(figsize=(5,14))\n",
        "  ax = f.add_subplot(121, projection='3d', azim = -90, elev=90)\n",
        "  ax.plot_surface(X,Y,Z, cmap=\"hot\", alpha=.8)\n",
        "  ax.set_xlabel(\"$x_1$\")\n",
        "  ax.set_ylabel(\"$x_2$\")\n",
        "  ax.set_zlabel(\"$t$\")\n",
        "\n",
        "  ax = f.add_subplot(122, projection='3d', azim = -60, elev=30)\n",
        "  ax.plot_surface(X,Y,Z, cmap=\"hot\", alpha=.8)\n",
        "  ax.set_zlim(-1,1)\n",
        "  ax.set_xlabel(\"$x_1$\")\n",
        "  ax.set_ylabel(\"$x_2$\")\n",
        "  ax.set_zlabel(\"$t$\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-keRppj8REAB"
      },
      "source": [
        "Now, we define our original data. This is just for visualization purposes, you do not have to modify this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7LNdvrPREAD"
      },
      "outputs": [],
      "source": [
        "# our data function that takes two parameters, x_1 and x_2\n",
        "def data(x_1, x_2):\n",
        "  return torch.cos(x_1) * torch.sin(x_2)\n",
        "\n",
        "# display our function in a three-dimensional range\n",
        "rge = numpy.arange(-3,3,0.1)\n",
        "X,Y = numpy.meshgrid(rge, rge)\n",
        "Z = data(torch.tensor(X), torch.tensor(Y)).numpy()\n",
        "plot_3d(X, Y, Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5N0xBJnREAE"
      },
      "source": [
        "### 1. (e) Autograd Function\n",
        "\n",
        "We want to implement the gradient that we have computed in (b) as a `torch.autograd.Function`.\n",
        "Remember that the output of the `backward` function are the gradients with respect to all input parameters of the `forward` function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89UA-j0tREAF"
      },
      "outputs": [],
      "source": [
        "from torch._C import wait\n",
        "class MyFunction(torch.autograd.Function):\n",
        "\n",
        "  # implement the forward propagation\n",
        "  @staticmethod\n",
        "  def forward(ctx, x, w):\n",
        "    # compute the output\n",
        "    output = torch.sum(x-w, dim=0)**2\n",
        "    # save required parameters for backward pass\n",
        "    ctx.save_for_backward(x, w)\n",
        "    return output\n",
        "\n",
        "  # implement Jacobian\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad):\n",
        "    # get results stored from forward pass\n",
        "    x, w = ctx.saved_tensors\n",
        "    # compute the derivatives\n",
        "    da/dw = -2(x-w)\n",
        "    return da/dw, None #because we do not need the da/dx -> None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mmm_fi2REAI"
      },
      "source": [
        "### 1. (f) Network Implementation\n",
        "\n",
        "We implement our network to combine the first layer with an activation function, and a fully-connected layer to produce our desired output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "XCwwwj3TREAJ",
        "outputId": "6c67073f-72e8-4611-8109-af2847e561ef"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-20073775c87d>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    self.activation = torch.nn.()\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "class Network(torch.nn.Module):\n",
        "  def __init__(self, K, D):\n",
        "    super(Network, self).__init__()\n",
        "    # we select our function defined above as the first layer that we apply\n",
        "    self.first_layer = MyFunction.apply\n",
        "\n",
        "    # We need to instantiate and initialize our weights\n",
        "    self.W = torch.nn.Parameter(torch.empty((K,D)))\n",
        "    # initialize the matrix between -3 and 3 (since the range of the inputs is (-3,3))\n",
        "    torch.nn.init.uniform_(self.W, -3, 3)\n",
        "\n",
        "    # We then instantiate the second fully-connected layer\n",
        "    self.secoond_layer = torch.nn.Linear(K, 1) #since this is a regression, the output is O=1\n",
        "\n",
        "    # anything else to instantiate here?\n",
        "    self.activation = torch.nn.Tanh()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # forward input through our custom function\n",
        "    a = self.first_layer(x)\n",
        "    \n",
        "    # possibly apply an activation function\n",
        "    h = self.activation(a)\n",
        "\n",
        "    # apply second layer\n",
        "    z = self.secoond_layer(h)\n",
        "\n",
        "    return z\n",
        "\n",
        "# instantiate a network with the desired parameters\n",
        "network = Network(6, D=x.shape[0]) #D could also have been defined like this in the constructor of Nework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPMDXn5TREAL"
      },
      "source": [
        "We implement a function that draws random samples from the input distribution.\n",
        "You can make use of this function, there is no need to modify it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aooWtR-REAM"
      },
      "outputs": [],
      "source": [
        "# provides a sample from the function that we want to approximate\n",
        "def sample():\n",
        "  # get a random input\n",
        "  x = torch.rand(2) * 6 - 3\n",
        "  # compute the target\n",
        "  t = data(x[0], x[1])[None]\n",
        "  # return both\n",
        "  return x, t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIDq6FIzREAN"
      },
      "source": [
        "### 1. (g) Network Training\n",
        "\n",
        "Finally, we train our network on 100000 samples, using a batch size of 1. We report the average loss for 10000 samples once they are processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNkl1AcLREAO"
      },
      "outputs": [],
      "source": [
        "# instantiate loss function and optimizer\n",
        "loss = torch.nn.MSELoss()\n",
        "optimizer = optimizer = torch.optim.Adam(network.parameters(), lr=0.0005, weight_decay=1e-05)\n",
        "\n",
        "#create variable to store train loss\n",
        "train_loss = 0.\n",
        "\n",
        "# iterate over 100000 samples\n",
        "for i in range(100000):\n",
        "  # obtain a sample\n",
        "  x, t = sample()\n",
        "  # train the network with this sample\n",
        "  optimizer.zero_grad()\n",
        "  z=network(x)\n",
        "  # ... compute loss from network output and target data\n",
        "  J=loss(z, x)\n",
        "  J.backward()\n",
        "  # ... perform parameter update\n",
        "  optimizer.step()\n",
        "  # ... remember loss\n",
        "  train_loss += J.item()\n",
        "\n",
        "  # compute average loss\n",
        "  avg_loss = train_loss/100000.\n",
        "  # report it after every 10000 iterations\n",
        "  if i % 10000 == 9999:\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdLR2cLKREAO"
      },
      "source": [
        "Finally, we plot the output of your network to visually see whether the data has been approximated well.\n",
        "We actually extend the range of the input samples to be $[-5,5]$ to see if the network has learned to extend the function well beyond the training range.\n",
        "Note that this is just for visualization purposes, you do not need to change this part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm9a8FGcREAP"
      },
      "outputs": [],
      "source": [
        "# define a range a little larger than our input range\n",
        "rge = numpy.arange(-5,5,0.1)\n",
        "X,Y = numpy.meshgrid(rge, rge)\n",
        "# compute the result of our network for the given range [-5,5]x[-5,5]\n",
        "Z = numpy.array([[network(torch.FloatTensor((X[i,j], Y[i,j]))).item() for j in range(len(rge))] for i in range(len(rge))])\n",
        "# plot the results\n",
        "plot_3d(X,Y,Z)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a29cabff5744fce69e08a959ab87b9e77a9f67b498d08783caa8c3bb16f23a00"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('DL')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "DL-FS22-Exam-Task1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}